{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN_basic.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNE4OhiJRN/IqlV+MdIRtlR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/peeyushsinghal/CNN/blob/master/CNN_basic.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eJ9bw-awIo-D",
        "colab_type": "text"
      },
      "source": [
        "Exploring to create CNN through basic libraries\n",
        "\n",
        "Architecture : Input Layer -> Conv Layer 1 -> Relu 1 -> Conv Layer 2 -> Relu 2 -> Maxpool layer -> Dense (Fully Connected) Layer -> Ouput"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L3PR8b3YIu-Y",
        "colab_type": "text"
      },
      "source": [
        "1. Importing Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HUIvE3hjIZ2q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt # for showing images\n",
        "import tensorflow as tf # only for importing keras dataset\n",
        "import random # for generating random number (image index)\n",
        "\n",
        "\n"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4GzpJ0QYI8nn",
        "colab_type": "text"
      },
      "source": [
        "2. Getting data : Importing the dataset - MNIST hand written digits https://keras.io/api/datasets/mnist/. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BPn26hBOJIgy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data(path=\"mnist.npz\")\n",
        "# Tuple of Numpy arrays: (x_train, y_train), (x_test, y_test)\n",
        "#x_train: uint8 arrays of grayscale image data with shapes (num_samples, 28, 28).\n",
        "#y_train: uint8 arrays of digit labels (integers in range 0-9) with shapes (num_samples,)"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ztUZMGtdJhZI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3d6acf39-b0af-4d1f-8f82-1b68c5eff57c"
      },
      "source": [
        "# Checking the downloaded data\n",
        "x_train.shape\n",
        "# around 60000 images"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 28, 28)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cRncx-BBJmdB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "f6fcdd9d-cfe9-4b3b-d251-83a9276a7e96"
      },
      "source": [
        "# visualizing the data\n",
        "n = random.randint(0,x_train.shape[0]-1)# generated a random integer between 0 and image index\n",
        "img = x_train[n].reshape((28, 28)) # using the index, get the image reshaped to 28, 28, [ understood by stackoverflow comments]\n",
        "label = y_train[n] # the label for the corresponding index\n",
        "print(\"Label: \",label)\n",
        "plt.imshow(img, cmap='gray')\n",
        "plt.show()"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Label:  3\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o7t2f011V8sC",
        "colab_type": "text"
      },
      "source": [
        "3. Normalizing Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UgtzpGmhLTtO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# normalising the image data set\n",
        "def normalise_data(data):\n",
        "  data=data.reshape(data.shape[0],28,28,1).astype('float32') # creating tensor by reshaping Image_set_size, 28, 28, 1\n",
        "  data= (data-int(np.mean(data)))/(int(np.std(data)))  # Normalize the images using standard normalization"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xE0rox6GMTZm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# normalising training data\n",
        "x_train = normalise_data(x_train)"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FdeWfFLKWNEY",
        "colab_type": "text"
      },
      "source": [
        "4. Hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ih8C-z7JS6Fv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Hyperparameters\n",
        "\n",
        "NUM_OUTPUT = 10 # output data\n",
        "LEARNING_RATE = 0.01\t#learning rate\n",
        "IMG_WIDTH = 28 # image width\n",
        "IMG_DEPTH = 1\n",
        "FILTER_SIZE=5 # assuming a square filter\n",
        "NUM_FILT1 = 8 # number of filters in layer 1\n",
        "NUM_FILT2 = 8 # number of filters in layer 2\n",
        "BATCH_SIZE = 20\n",
        "NUM_EPOCHS = 2\t # number of iterations\n",
        "MU = 0.95\n",
        "\n",
        "PICKLE_FILE = 'output.pickle'\n",
        "# PICKLE_FILE = 'trained.pickle'"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tf8HxcInWxtH",
        "colab_type": "text"
      },
      "source": [
        "5. Initializing parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N-Td6SadWsCu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "filter_1 ={} # weights of filters of layer 1\n",
        "filter_2 ={} # weights of filters of layer 2\n",
        "bias_1 ={} # bias of filter of layer 1\n",
        "bias_2 ={} # bias of filter of layer 2"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TQtDIRBYYU85",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#initializes layer with filter weights for each filter and bias\n",
        "def init_layer(num_filter,filter_size=FILTER_SIZE,img_depth = IMG_DEPTH):\n",
        "  list_filter = list()\n",
        "  for i in range(0,num_filter):\n",
        "    initializer = tf.keras.initializers.RandomNormal(mean=0.0, stddev=1, seed=None)\n",
        "    filter = initializer(shape=(filter_size,filter_size))\n",
        "    list_filter.append(filter)\n",
        "  bias=0\n",
        "  return list_filter,bias"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FuTAjpooZgXj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# initializing layer 1\n",
        "filter_1,bias_1 = init_layer(NUM_FILT1)"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sVxOfrOv_2nU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# initializing layer 2\n",
        "filter_2, bias_2 = init_layer(NUM_FILT2)"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RM46hsvUYUEK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VBtyRSTkIoH1",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    }
  ]
}